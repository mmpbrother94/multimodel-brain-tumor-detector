{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7059,
     "status": "ok",
     "timestamp": 1740661303558,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "YHDligrIok7o",
    "outputId": "5ac26ce3-5ece-4d83-fc3a-db972925bab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185563,
     "status": "ok",
     "timestamp": 1740661489104,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "uGMjNWLevMCh",
    "outputId": "f34e1f62-f6c9-4550-957c-3bde71aaefb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Main folder contents: ['no', 'yes']\n",
      "Yes folder: /content/drive/MyDrive/BrainMRIzip/BrainMRI/yes Exists? True\n",
      "No folder: /content/drive/MyDrive/BrainMRIzip/BrainMRI/no Exists? True\n",
      "Files in yes_folder: ['Y117.JPG', 'Y100.JPG', 'Y13.jpg', 'Y14.jpg', 'Y112.JPG', 'Y114.JPG', 'Y116.JPG', 'Y11.jpg', 'Y105.jpg', 'Y111.JPG', 'Y147.JPG', 'Y104.jpg', 'Y113.JPG', 'Y12.jpg', 'Y1.jpg', 'Y101.jpg', 'Y107.jpg', 'Y102.jpg', 'Y115.JPG', 'Y10.jpg', 'Y106.jpg', 'Y120.JPG', 'Y109.JPG', 'Y108.jpg', 'Y146.JPG', 'Y103.jpg', 'Y186.jpg', 'Y170.JPG', 'Y185.jpg', 'Y183.jpg', 'Y159.JPG', 'Y157.JPG', 'Y166.JPG', 'Y18.JPG', 'Y187.jpg', 'Y188.jpg', 'Y182.JPG', 'Y181.jpg', 'Y20.jpg', 'Y154.jpg', 'Y15.jpg', 'Y148.JPG', 'Y22.jpg', 'Y156.JPG', 'Y169.jpg', 'Y153.jpg', 'Y163.JPG', 'Y167.JPG', 'Y193.JPG', 'Y161.JPG', 'Y184.JPG', 'Y21.jpg', 'Y168.jpg', 'Y164.JPG', 'Y155.JPG', 'Y16.JPG', 'Y195.JPG', 'Y19.JPG', 'Y17.jpg', 'Y2.jpg', 'Y162.jpg', 'Y194.jpg', 'Y158.JPG', 'Y165.JPG', 'Y180.jpg', 'Y160.JPG', 'Y192.JPG', 'Y250.jpg', 'Y34.jpg', 'Y36.JPG', 'Y254.jpg', 'Y257.jpg', 'Y35.jpg', 'Y27.jpg', 'Y245.jpg', 'Y37.jpg', 'Y28.jpg', 'Y39.jpg', 'Y252.jpg', 'Y25.jpg', 'Y249.JPG', 'Y30.jpg', 'Y26.jpg', 'Y23.JPG', 'Y41.jpg', 'Y40.JPG', 'Y251.JPG', 'Y24.jpg', 'Y4.jpg', 'Y256.JPG', 'Y33.jpg', 'Y246.JPG', 'Y31.jpg', 'Y3.jpg', 'Y242.JPG', 'Y247.JPG', 'Y29.jpg', 'Y243.JPG', 'Y259.JPG', 'Y32.jpg', 'Y258.JPG', 'Y248.JPG', 'Y244.JPG', 'Y253.JPG', 'Y38.jpg', 'Y255.JPG', 'Y59.JPG', 'Y78.jpg', 'Y62.jpg', 'Y73.jpg', 'Y56.jpg', 'Y58.JPG', 'Y76.jpg', 'Y81.jpg', 'Y71.JPG', 'Y8.jpg', 'Y70.jpg', 'Y65.JPG', 'Y50.JPG', 'Y67.JPG', 'Y6.jpg', 'Y77.jpg', 'Y47.JPG', 'Y45.JPG', 'Y52.jpg', 'Y66.JPG', 'Y82.jpg', 'Y60.jpg', 'Y53.jpg', 'Y46.jpg', 'Y79.jpg', 'Y49.JPG', 'Y85.JPG', 'Y61.jpg', 'Y7.jpg', 'Y55.jpg', 'Y69.jpg', 'Y44.JPG', 'Y42.jpg', 'Y51.jpg', 'Y54.jpg', 'Y74.jpg', 'Y75.JPG', 'Y90.jpg', 'Y91.jpg', 'Y92.png', 'Y99.JPG', 'Y96.jpg', 'Y92.jpg', 'Y97.JPG', 'Y95.jpg', 'Y89.JPG', 'Y98.JPG', 'Y9.jpg', 'Y86.JPG']\n",
      "Files in no_folder: ['19 no.jpg', '17 no.jpg', '21 no.jpg', '15 no.jpg', '10 no.jpg', '14 no.jpg', '22 no.jpg', '18 no.jpg', '12 no.jpg', '20 no.jpg', '23 no.jpg', '11 no.jpg', '2 no.jpeg', '1 no.jpeg', '13 no.jpg', '40 no.jpg', '37 no.jpg', '50 no.jpg', '39 no.jpg', '7 no.jpg', '33 no.jpg', '9 no.jpg', '28 no.jpg', '29 no.jpg', '43 no.jpg', '5 no.jpg', '26 no.jpg', '36 no.jpg', '44no.jpg', '47 no.jpg', '24 no.jpg', '38 no.jpg', 'N1.JPG', '31 no.jpg', '3 no.jpg', '25 no.jpg', '41 no.jpg', '48 no.jpeg', '34 no.jpg', '32 no.jpg', '8 no.jpg', '49 no.jpg', '42 no.jpg', '45 no.jpg', '35 no.jpg', '30 no.jpg', '46 no.jpg', '4 no.jpg', '6 no.jpg', '27 no.jpg', 'N11.jpg', 'no 9.png', 'N6.jpg', 'no 98.jpg', 'no 1.jpg', 'N16.jpg', 'no 5.jpeg', 'N5.jpg', 'no 90.jpg', 'no 89.jpg', 'N3.jpg', 'N19.JPG', 'no 6.jpg', 'no 7.jpeg', 'no.jpg', 'no 97.jpg', 'N21.jpg', 'no 4.jpg', 'no 8.jpg', 'no 923.jpg', 'no 91.jpeg', 'no 100.jpg', 'no 96.jpg', 'N2.JPG', 'N15.jpg', 'N26.JPG', 'N22.JPG', 'N20.JPG', 'no 94.jpg', 'no 10.jpg', 'N17.jpg', 'no 92.jpg', 'no 2.jpg', 'no 99.jpg', 'no 3.jpg', 'no 95.jpg', 'No16.jpg', 'No13.jpg', 'No15.jpg', 'No19.jpg', 'No18.jpg', 'No12.jpg', 'No22.jpg', 'No17.jpg', 'No21.jpg', 'No20.jpg', 'No14.jpg', 'No11.jpg']\n",
      "Loaded 171 images and 171 reports.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_images_and_labels(main_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Debug paths\n",
    "    yes_folder = os.path.join(main_folder, 'yes')  # Lowercase 'yes'\n",
    "    no_folder = os.path.join(main_folder, 'no')    # Lowercase 'no'\n",
    "    print(\"Yes folder:\", yes_folder, \"Exists?\", os.path.isdir(yes_folder))\n",
    "    print(\"No folder:\", no_folder, \"Exists?\", os.path.isdir(no_folder))\n",
    "\n",
    "    # Load Yes (tumor) images\n",
    "    if os.path.isdir(yes_folder):\n",
    "        yes_files = os.listdir(yes_folder)\n",
    "        print(\"Files in yes_folder:\", yes_files)\n",
    "        for filename in yes_files:\n",
    "            if filename.endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(yes_folder, filename)).resize((128, 128)).convert('L')\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append('Yes')\n",
    "    else:\n",
    "        print(\"Yes folder not found!\")\n",
    "\n",
    "    # Load No (normal) images\n",
    "    if os.path.isdir(no_folder):\n",
    "        no_files = os.listdir(no_folder)\n",
    "        print(\"Files in no_folder:\", no_files)\n",
    "        for filename in no_files:\n",
    "            if filename.endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(no_folder, filename)).resize((128, 128)).convert('L')\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append('No')\n",
    "    else:\n",
    "        print(\"No folder not found!\")\n",
    "\n",
    "    return np.array(images), labels\n",
    "\n",
    "def generate_reports(labels):\n",
    "    reports = []\n",
    "    for label in labels:\n",
    "        if label == \"Yes\":\n",
    "            reports.append(\"Findings: Tumor detected in brain tissue\")\n",
    "        elif label == \"No\":\n",
    "            reports.append(\"Findings: No abnormalities observed in brain tissue\")\n",
    "    return reports\n",
    "\n",
    "# Mount Drive (force remount if needed)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Check contents\n",
    "main_folder = '/content/drive/MyDrive/BrainMRIzip/BrainMRI'\n",
    "print(\"Main folder contents:\", os.listdir(main_folder))\n",
    "\n",
    "# Load data\n",
    "images, labels = load_images_and_labels(main_folder)\n",
    "reports = generate_reports(labels)\n",
    "\n",
    "# Tokenize reports\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reports)\n",
    "report_sequences = tokenizer.texts_to_sequences(reports)\n",
    "max_length = max(len(seq) for seq in report_sequences) if report_sequences else 0  # Avoid empty sequence error\n",
    "report_padded = tf.keras.preprocessing.sequence.pad_sequences(report_sequences, maxlen=max_length)\n",
    "vocab_size = len(tokenizer.word_index) + 1 if tokenizer.word_index else 0\n",
    "\n",
    "print(f\"Loaded {len(images)} images and {len(reports)} reports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 25754,
     "status": "ok",
     "timestamp": 1740661514848,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "EAhj29StxckG",
    "outputId": "836f47d1-2380-4408-e646-7ee54327911f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Main folder contents: ['no', 'yes']\n",
      "Yes folder: /content/drive/MyDrive/BrainMRIzip/BrainMRI/yes Exists? True\n",
      "No folder: /content/drive/MyDrive/BrainMRIzip/BrainMRI/no Exists? True\n",
      "Files in yes_folder: ['Y117.JPG', 'Y100.JPG', 'Y13.jpg', 'Y14.jpg', 'Y112.JPG', 'Y114.JPG', 'Y116.JPG', 'Y11.jpg', 'Y105.jpg', 'Y111.JPG', 'Y147.JPG', 'Y104.jpg', 'Y113.JPG', 'Y12.jpg', 'Y1.jpg', 'Y101.jpg', 'Y107.jpg', 'Y102.jpg', 'Y115.JPG', 'Y10.jpg', 'Y106.jpg', 'Y120.JPG', 'Y109.JPG', 'Y108.jpg', 'Y146.JPG', 'Y103.jpg', 'Y186.jpg', 'Y170.JPG', 'Y185.jpg', 'Y183.jpg', 'Y159.JPG', 'Y157.JPG', 'Y166.JPG', 'Y18.JPG', 'Y187.jpg', 'Y188.jpg', 'Y182.JPG', 'Y181.jpg', 'Y20.jpg', 'Y154.jpg', 'Y15.jpg', 'Y148.JPG', 'Y22.jpg', 'Y156.JPG', 'Y169.jpg', 'Y153.jpg', 'Y163.JPG', 'Y167.JPG', 'Y193.JPG', 'Y161.JPG', 'Y184.JPG', 'Y21.jpg', 'Y168.jpg', 'Y164.JPG', 'Y155.JPG', 'Y16.JPG', 'Y195.JPG', 'Y19.JPG', 'Y17.jpg', 'Y2.jpg', 'Y162.jpg', 'Y194.jpg', 'Y158.JPG', 'Y165.JPG', 'Y180.jpg', 'Y160.JPG', 'Y192.JPG', 'Y250.jpg', 'Y34.jpg', 'Y36.JPG', 'Y254.jpg', 'Y257.jpg', 'Y35.jpg', 'Y27.jpg', 'Y245.jpg', 'Y37.jpg', 'Y28.jpg', 'Y39.jpg', 'Y252.jpg', 'Y25.jpg', 'Y249.JPG', 'Y30.jpg', 'Y26.jpg', 'Y23.JPG', 'Y41.jpg', 'Y40.JPG', 'Y251.JPG', 'Y24.jpg', 'Y4.jpg', 'Y256.JPG', 'Y33.jpg', 'Y246.JPG', 'Y31.jpg', 'Y3.jpg', 'Y242.JPG', 'Y247.JPG', 'Y29.jpg', 'Y243.JPG', 'Y259.JPG', 'Y32.jpg', 'Y258.JPG', 'Y248.JPG', 'Y244.JPG', 'Y253.JPG', 'Y38.jpg', 'Y255.JPG', 'Y59.JPG', 'Y78.jpg', 'Y62.jpg', 'Y73.jpg', 'Y56.jpg', 'Y58.JPG', 'Y76.jpg', 'Y81.jpg', 'Y71.JPG', 'Y8.jpg', 'Y70.jpg', 'Y65.JPG', 'Y50.JPG', 'Y67.JPG', 'Y6.jpg', 'Y77.jpg', 'Y47.JPG', 'Y45.JPG', 'Y52.jpg', 'Y66.JPG', 'Y82.jpg', 'Y60.jpg', 'Y53.jpg', 'Y46.jpg', 'Y79.jpg', 'Y49.JPG', 'Y85.JPG', 'Y61.jpg', 'Y7.jpg', 'Y55.jpg', 'Y69.jpg', 'Y44.JPG', 'Y42.jpg', 'Y51.jpg', 'Y54.jpg', 'Y74.jpg', 'Y75.JPG', 'Y90.jpg', 'Y91.jpg', 'Y92.png', 'Y99.JPG', 'Y96.jpg', 'Y92.jpg', 'Y97.JPG', 'Y95.jpg', 'Y89.JPG', 'Y98.JPG', 'Y9.jpg', 'Y86.JPG']\n",
      "Files in no_folder: ['19 no.jpg', '17 no.jpg', '21 no.jpg', '15 no.jpg', '10 no.jpg', '14 no.jpg', '22 no.jpg', '18 no.jpg', '12 no.jpg', '20 no.jpg', '23 no.jpg', '11 no.jpg', '2 no.jpeg', '1 no.jpeg', '13 no.jpg', '40 no.jpg', '37 no.jpg', '50 no.jpg', '39 no.jpg', '7 no.jpg', '33 no.jpg', '9 no.jpg', '28 no.jpg', '29 no.jpg', '43 no.jpg', '5 no.jpg', '26 no.jpg', '36 no.jpg', '44no.jpg', '47 no.jpg', '24 no.jpg', '38 no.jpg', 'N1.JPG', '31 no.jpg', '3 no.jpg', '25 no.jpg', '41 no.jpg', '48 no.jpeg', '34 no.jpg', '32 no.jpg', '8 no.jpg', '49 no.jpg', '42 no.jpg', '45 no.jpg', '35 no.jpg', '30 no.jpg', '46 no.jpg', '4 no.jpg', '6 no.jpg', '27 no.jpg', 'N11.jpg', 'no 9.png', 'N6.jpg', 'no 98.jpg', 'no 1.jpg', 'N16.jpg', 'no 5.jpeg', 'N5.jpg', 'no 90.jpg', 'no 89.jpg', 'N3.jpg', 'N19.JPG', 'no 6.jpg', 'no 7.jpeg', 'no.jpg', 'no 97.jpg', 'N21.jpg', 'no 4.jpg', 'no 8.jpg', 'no 923.jpg', 'no 91.jpeg', 'no 100.jpg', 'no 96.jpg', 'N2.JPG', 'N15.jpg', 'N26.JPG', 'N22.JPG', 'N20.JPG', 'no 94.jpg', 'no 10.jpg', 'N17.jpg', 'no 92.jpg', 'no 2.jpg', 'no 99.jpg', 'no 3.jpg', 'no 95.jpg', 'No16.jpg', 'No13.jpg', 'No15.jpg', 'No19.jpg', 'No18.jpg', 'No12.jpg', 'No22.jpg', 'No17.jpg', 'No21.jpg', 'No20.jpg', 'No14.jpg', 'No11.jpg']\n",
      "Loaded 253 images and 253 reports.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,783,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">329,994</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │      \u001b[38;5;34m25,783,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │         \u001b[38;5;34m329,994\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,113,034</span> (99.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,113,034\u001b[0m (99.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,113,034</span> (99.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,113,034\u001b[0m (99.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "\n",
    "# Load images and labels\n",
    "def load_images_and_labels(main_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    yes_folder = os.path.join(main_folder, 'yes')\n",
    "    no_folder = os.path.join(main_folder, 'no')\n",
    "    print(\"Yes folder:\", yes_folder, \"Exists?\", os.path.isdir(yes_folder))\n",
    "    print(\"No folder:\", no_folder, \"Exists?\", os.path.isdir(no_folder))\n",
    "\n",
    "    if os.path.isdir(yes_folder):\n",
    "        yes_files = os.listdir(yes_folder)\n",
    "        print(\"Files in yes_folder:\", yes_files)\n",
    "        for filename in yes_files:\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img = Image.open(os.path.join(yes_folder, filename)).resize((128, 128)).convert('L')\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append('Yes')\n",
    "    if os.path.isdir(no_folder):\n",
    "        no_files = os.listdir(no_folder)\n",
    "        print(\"Files in no_folder:\", no_files)\n",
    "        for filename in no_files:\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img = Image.open(os.path.join(no_folder, filename)).resize((128, 128)).convert('L')\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append('No')\n",
    "    return np.array(images), labels\n",
    "\n",
    "def generate_reports(labels):\n",
    "    reports = []\n",
    "    for label in labels:\n",
    "        if label == \"Yes\":\n",
    "            reports.append(\"Findings: Tumor detected in brain tissue\")\n",
    "        elif label == \"No\":\n",
    "            reports.append(\"Findings: No abnormalities observed in brain tissue\")\n",
    "    return reports\n",
    "\n",
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Check contents\n",
    "main_folder = '/content/drive/MyDrive/BrainMRIzip/BrainMRI'\n",
    "print(\"Main folder contents:\", os.listdir(main_folder))\n",
    "\n",
    "# Load data\n",
    "images, labels = load_images_and_labels(main_folder)\n",
    "reports = generate_reports(labels)\n",
    "\n",
    "# Tokenize reports\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reports)\n",
    "report_sequences = tokenizer.texts_to_sequences(reports)\n",
    "max_length = max(len(seq) for seq in report_sequences) if report_sequences else 0\n",
    "report_padded = tf.keras.preprocessing.sequence.pad_sequences(report_sequences, maxlen=max_length)\n",
    "vocab_size = len(tokenizer.word_index) + 1 if tokenizer.word_index else 0\n",
    "\n",
    "print(f\"Loaded {len(images)} images and {len(reports)} reports.\")\n",
    "\n",
    "# Build CNN\n",
    "def build_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build LSTM (fixed to output sequences)\n",
    "def build_lstm(vocab_size, max_length):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.LSTM(128, return_sequences=True, input_shape=(max_length, 256)),\n",
    "        layers.LSTM(128, return_sequences=True),  # Keep sequence output\n",
    "        layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))  # Predict word at each timestep\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Combine\n",
    "cnn = build_cnn()\n",
    "lstm = build_lstm(vocab_size, max_length)\n",
    "image_input = layers.Input(shape=(128, 128, 1))\n",
    "cnn_output = cnn(image_input)\n",
    "cnn_output = layers.RepeatVector(max_length)(cnn_output)  # Shape: (batch, max_length, 256)\n",
    "lstm_output = lstm(cnn_output)  # Shape: (batch, max_length, vocab_size)\n",
    "model = tf.keras.Model(inputs=image_input, outputs=lstm_output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19201,
     "status": "ok",
     "timestamp": 1740661534022,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "Lk3WjhvUUCWF",
    "outputId": "65de1141-5b2d-4697-b1d8-3b1769577481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - loss: 2.0936 - val_loss: 2.0254\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5841 - val_loss: 1.7834\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1037 - val_loss: 1.4875\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.8183 - val_loss: 1.0903\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.6192 - val_loss: 1.0984\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4685 - val_loss: 0.8027\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.3042 - val_loss: 0.8218\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2374 - val_loss: 0.6763\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1455 - val_loss: 0.6388\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0932 - val_loss: 0.6339\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0711 - val_loss: 0.7060\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0474 - val_loss: 0.7509\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0334 - val_loss: 0.7763\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0269 - val_loss: 0.8304\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0223 - val_loss: 0.8599\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0173 - val_loss: 0.8656\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0152 - val_loss: 0.8832\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0127 - val_loss: 0.9304\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0117 - val_loss: 0.9591\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0100 - val_loss: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f58f1dd33d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "images = images.reshape(-1, 128, 128, 1)\n",
    "report_labels = report_padded  # Shape: (batch, max_length) - no extra dim needed\n",
    "model.fit(images, report_labels, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 1826,
     "status": "error",
     "timestamp": 1740678208252,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "cE3rh9e8VVLx",
    "outputId": "b7ec6639-895d-4f6d-c2cb-34534cf17c77"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e324a56fa61d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/brain_tumor_report_generator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/tokenizer.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save('/content/brain_tumor_report_generator.h5')\n",
    "with open('/content/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('/content/brain_tumor_report_generator.h5')\n",
    "files.download('/content/tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740661731720,
     "user": {
      "displayName": "Manohar Kumar",
      "userId": "03622389446795947199"
     },
     "user_tz": -330
    },
    "id": "NrJqucYuWYiY",
    "outputId": "c8783121-64b1-4ad9-99e3-45f3ce5a9743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Test Report: findings tumor detected in brain tissue\n"
     ]
    }
   ],
   "source": [
    "# Test in Colab (corrected)\n",
    "test_img = Image.open('/content/drive/MyDrive/BrainMRIzip/BrainMRI/yes/Y1.jpg').resize((128, 128)).convert('L')\n",
    "test_img = np.array(test_img) / 255.0\n",
    "test_img = test_img.reshape(1, 128, 128, 1)\n",
    "report_seq = model.predict(test_img)  # Shape: (1, max_length, vocab_size)\n",
    "report_words = []\n",
    "for timestep in report_seq[0]:\n",
    "    word_idx = np.argmax(timestep)\n",
    "    if word_idx > 0:  # Skip padding (0)\n",
    "        try:\n",
    "            word = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(word_idx)]\n",
    "            report_words.append(word)\n",
    "        except ValueError:\n",
    "            continue  # Skip if word_idx isn’t in word_index (shouldn’t happen but adds robustness)\n",
    "report = ' '.join(report_words)\n",
    "print(\"Test Report:\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mULunczwWtMx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOC7xudwZo17Hw1c2qmer+0",
   "mount_file_id": "1boCdjZy7Def1Uk02uEYZ58ghFCH3h5hL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
